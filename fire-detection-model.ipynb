{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-13T06:28:35.170323Z","iopub.status.busy":"2023-02-13T06:28:35.169506Z","iopub.status.idle":"2023-02-13T06:28:43.566654Z","shell.execute_reply":"2023-02-13T06:28:43.565259Z","shell.execute_reply.started":"2023-02-13T06:28:35.170177Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Importing Required Libraries.\n","from PIL import Image\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import keras\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-13T06:28:43.569634Z","iopub.status.busy":"2023-02-13T06:28:43.568954Z","iopub.status.idle":"2023-02-13T06:29:56.888870Z","shell.execute_reply":"2023-02-13T06:29:56.886166Z","shell.execute_reply.started":"2023-02-13T06:28:43.569599Z"},"trusted":true},"outputs":[],"source":["piclist=[]\n","\n","# Loading fire images, using PIL.image to resize.\n","for file in os.listdir(\"/kaggle/input/fire-dataset/fire_dataset/fire_images\"):\n","    # Resizing and converting to numpy array.\n","    img=np.array(Image.open(f\"/kaggle/input/fire-dataset/fire_dataset/fire_images/{file}\").resize((86,48), Image.Resampling.LANCZOS))\n","    # checking if resize was successful, then appending the np array to list.\n","    if img.shape==(48,86,3):\n","        piclist.append(img)\n","print (len(piclist))\n","\n","# Loading non-fire images, using PIL.Image and resize.\n","for file in os.listdir(\"/kaggle/input/fire-dataset/fire_dataset/non_fire_images\"):\n","    # Resizing and converting to numpy array.\n","    img=np.array(Image.open(f\"/kaggle/input/fire-dataset/fire_dataset/non_fire_images/{file}\").resize((86,48), Image.Resampling.LANCZOS))\n","    # checking if resize was successful, then appending the np array to list.\n","    if img.shape==(48,86,3):\n","        piclist.append(img)\n","print (len(piclist))\n","\n","# stacking the individual arrays in piclist into a 3D numpy array.\n","TrainStack=np.stack(piclist)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-13T06:29:56.892242Z","iopub.status.busy":"2023-02-13T06:29:56.890670Z","iopub.status.idle":"2023-02-13T06:29:56.900314Z","shell.execute_reply":"2023-02-13T06:29:56.898780Z","shell.execute_reply.started":"2023-02-13T06:29:56.892190Z"},"trusted":true},"outputs":[],"source":["# Creating binary labels for each image.\n","# 0 = non-fire & 1 = fire.\n","labels=[[0]*751+[1]*(990-751)]\n","\n","# flatten the multi-dimentional array, returns a one-dimentional array.\n","labels=np.array(labels).flatten()\n","\n","# converting the labels into one-hot encoding.\n","y = to_categorical(labels).astype(int)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-13T06:29:56.902814Z","iopub.status.busy":"2023-02-13T06:29:56.902461Z","iopub.status.idle":"2023-02-13T06:29:56.920257Z","shell.execute_reply":"2023-02-13T06:29:56.918838Z","shell.execute_reply.started":"2023-02-13T06:29:56.902782Z"},"trusted":true},"outputs":[],"source":["# Spliting data into training & testing sets using `train_test_split` from the sklearn.model_selection module.\n","# X_train, X_test and y_train, ytest are the output for the training and testing data.  \n","X_train,X_test,y_train,y_test = train_test_split(TrainStack,y,test_size=0.3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-13T06:29:56.923951Z","iopub.status.busy":"2023-02-13T06:29:56.923531Z","iopub.status.idle":"2023-02-13T06:29:56.939511Z","shell.execute_reply":"2023-02-13T06:29:56.937755Z","shell.execute_reply.started":"2023-02-13T06:29:56.923915Z"},"trusted":true},"outputs":[],"source":["def build_model(input_shape):\n","    \"\"\"\n","    Function that defines a Neural Network API, using the keras API.\n","    \n","    @input_shape: Tuple of the shape size and rgb example (48,86,3)\n","    Returns: Keras, Neural Network Model.\n","    \"\"\"\n","    # Define input layer.\n","    inputs = keras.layers.Input(shape=input_shape)\n","    x = inputs\n","    # Defining the first convolutional layer: with 32 filters of size (3,3) to the input data.\n","    # Using the `relu` (rectified linear unit) activation function, that'll replace the negative values in the input with zero.\n","    # Kernel initializer specifies the layer weight, `he_uniform` is a variance sccaling initializer.\n","    x = keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform')(x)\n","    # Defining the Max Pooling Layer, performs down-sampling of the input data by taking the max value from a (2, 2) window.\n","    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n","    # Defining the 2nd  Convolutional layer:, applying 64 filters.\n","    x = keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform')(x)\n","    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x) # Defining the 2nd Max Pooling Layer.\n","    # Batch Normalization layer: normalizes the activations of the previous layer by subtracting the batch mean and \n","    # dividing by the batch standard deviation.\n","    x = keras.layers.BatchNormalization()(x)\n","    # Defining the 3rd Convolutional layer.\n","    x = keras.layers.Conv2D(128, kernel_size=(3,3), activation='relu', kernel_initializer='he_uniform')(x)\n","    x = keras.layers.MaxPooling2D(pool_size=(2,2))(x) # Defining the 3rd Pax Pooling Layer.\n","    # Flatten layer: This layer flattens the output of the previous layer into a 1D tensor, \n","    # which is required for input to the next dense layer.\n","    x = keras.layers.Flatten()(x)\n","    # Dense layer with 128 neurons and `relu` activation: applies a dense connection to the input data\n","    # each neuron in the layer is connected to all the neurons in the previous later.\n","    x = keras.layers.Dense(128, activation=\"relu\")(x)\n","    # Randomly sets 40% of neurons to zero during each forward pass to prevent overfitting.\n","    x = keras.layers.Dropout(0.4)(x)\n","    # Dense Layer with 1024 neurons and `relu` activation.\n","    x = keras.layers.Dense(1024, activation=\"relu\")(x) \n","    x = keras.layers.Dropout(0.4)(x) # Randomly sets 40% of neurons to zero during each forward pass to prevent overfitting.\n","    # Dense layer with 2 neurons and `softmax` activation: the output layer with 2 neurons corresponding \n","    # to the 2 possible classes. The `softmax` activation function is used to produce a probability-like output for each class.\n","    x = keras.layers.Dense(2, activation=\"softmax\")(x)\n","    # returns a Keras Model Instance, it consists of all the layers and the tensors connected between them allowing \n","    # to be used for training and inference.\n","    return keras.Model(inputs, x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-13T06:29:56.942154Z","iopub.status.busy":"2023-02-13T06:29:56.941573Z","iopub.status.idle":"2023-02-13T06:34:41.836125Z","shell.execute_reply":"2023-02-13T06:34:41.835096Z","shell.execute_reply.started":"2023-02-13T06:29:56.942106Z"},"trusted":true},"outputs":[],"source":["# Training the Model.\n","\n","# Defining learning rate scheduling, learning rate is multiplied by a factor of `0.96` after `100000 steps of training.\n","# This helps to gradually decrease the learning rate, which can make the training process smoother.\n","initial_learning_rate = 0.00001\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True)\n","\n","# List of Metrics that will be used by the model to evaluate its performance during the training.\n","# here we'll have measures such as true/false positive/negative, caterogical accuracy, precision, recall,\n","# area under the ROC Curve and area under the precision-recall curve.\n","METRICS = [\n","      keras.metrics.TruePositives(name='tp'),\n","      keras.metrics.FalsePositives(name='fp'),\n","      keras.metrics.TrueNegatives(name='tn'),\n","      keras.metrics.FalseNegatives(name='fn'), \n","      keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n","      keras.metrics.Precision(name='precision'),\n","      keras.metrics.Recall(name='recall'),\n","      keras.metrics.AUC(name='auc'),\n","      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n","]\n","\n","\n","\n","model=build_model((48,86,3)) # Build the model using the function that will define the architecture of the model.\n","\n","# Callback to save the best model weights to a file named `fire.h5` after each epoch.\n","checkpoint_cb = keras.callbacks.ModelCheckpoint(\n","    \"fire.h5\", save_best_only=True\n",")\n","# stop training if validation accuracy doesn't improve for `100` epochs.\n","early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_categorical_accuracy\", patience=100)\n","# model.summary()\n","\n","# Compiling the model using categorical crossentropy loss, an Adam optimizer with the learning rate defined by lr_schedule,\n","# and the metrics defined in METRICS.\n","model.compile(loss='categorical_crossentropy',\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n","    metrics=METRICS)\n","# The model is then trained on the training data X_train and y_train, evaluated on the validation data X_test and y_test,\n","# with a batch size of 10 and 100 epochs. The training process is monitored by the checkpoint_cb and early_stopping_cb callbacks.\n","# The training history is stored in the History variable.\n","History=model.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=10,epochs=100,callbacks=[checkpoint_cb, early_stopping_cb],verbose=1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-13T06:34:41.838668Z","iopub.status.busy":"2023-02-13T06:34:41.837711Z","iopub.status.idle":"2023-02-13T06:34:42.072609Z","shell.execute_reply":"2023-02-13T06:34:42.071248Z","shell.execute_reply.started":"2023-02-13T06:34:41.838626Z"},"trusted":true},"outputs":[],"source":["# plot a graph of the validation categorical accuracy over the epochs. \n","# `History.history['val_categorical_accuracy'] is a list of the validation categorical accuracy at the end of each epoch.\n","plt.plot(History.history['val_categorical_accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-13T06:34:42.074630Z","iopub.status.busy":"2023-02-13T06:34:42.074247Z","iopub.status.idle":"2023-02-13T06:34:44.383073Z","shell.execute_reply":"2023-02-13T06:34:44.381864Z","shell.execute_reply.started":"2023-02-13T06:34:42.074595Z"},"trusted":true},"outputs":[],"source":["firelist=['FIRE',\"NOT A FIRE\"]\n","\n","CustomDict={}\n","\n","# Populating the CustomDict dictionary with 25 random entries.\n","for _ in range(25):\n","    # Generating a random int between 0 and 989.\n","    r=np.random.randint(0,990)\n","    # r- th entry in the TrainStack arrya is paired with the true Label, Fire or Not-Fire, and the prediction made by the model\n","    # when fed when fed the same image stored in the TrainStack[r].\n","    # The true label is obtained by finding the maximum index of the y[r] array, which is a one-hot encoded representation of the label.\n","    # The np.argmax function returns the index of the maximum value in the input array, which in this case corresponds to the class label.\n","    # The predicted label is obtained by passing np.expand_dims(TrainStack[r], axis=0) through the model using the model.predict method.\n","    # This results in a one-hot encoded prediction that is transformed into the class label in the same way as the true label.\n","    # Finally, the image, true label, and predicted label are stored in the CustomDict dictionary as a tuple. \n","    CustomDict[r]=TrainStack[r],firelist[np.argmax(y[r])],firelist[np.argmax(model.predict(np.expand_dims(TrainStack[r],axis=0)))]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-13T06:34:44.384970Z","iopub.status.busy":"2023-02-13T06:34:44.384594Z","iopub.status.idle":"2023-02-13T06:34:49.483864Z","shell.execute_reply":"2023-02-13T06:34:49.482876Z","shell.execute_reply.started":"2023-02-13T06:34:44.384923Z"},"trusted":true},"outputs":[],"source":["# Creating a 5x5 subplot figure and plots 25 randomly selected images from the TrainStack data set. \n","# The actual and predicted class of each image is displayed as a label below the image.\n","fig, axs = plt.subplots(5,5,figsize=(25,25)) # creates a 5x5 subplot figure with a figure size of 25x25. axs is an array of subplots.\n","# loops over the first 25 elements of CustomDict, getting the key of the element in CustomDict and the marker == index of the element.\n","for key,marker in zip(CustomDict,range(25)):\n","    # plots the image stored in the first element of CustomDict[key] on the current subplot specified by axs[marker//5,marker%5]\n","    axs[marker//5,marker%5].imshow(CustomDict[key][0])\n","    # sets the x label of the current subplot to a string that includes both the actual and predicted class of the image. \n","    # The actual class is stored in the second element of the value of CustomDict[key] and the predicted class is stored in the third element. \n","    # The fontsize is set to 20.\n","    axs[marker//5,marker%5].set_xlabel(\"Pred: \"+str(CustomDict[key][2]+' Actu: '+str(CustomDict[key][1])),fontsize = 20.0)\n","    \n","\n","fig.tight_layout() # automatically adjusts the subplots so that they fit nicely within the figure.\n","\n","plt.savefig(f\"Fire.jpg\") # saves the figure to a JPEG image file named \"Fire.jpg"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"vscode":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}}},"nbformat":4,"nbformat_minor":4}
